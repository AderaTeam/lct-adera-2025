# adera-lct-2025

## Краткое описание продукта и его функциональности
Продукт представляет из себя две системы: аналитический дашборд и модель обработки пользовательских отзывов
- Дашборд представляет следующую информацию:
    - Тональность и процентиль отзывов - положительные, нейтральные, негативные, их соотношение
    - Динамика тональность - изменение процентовки отзывов разных тональностей за выбранный период
    - Динамика количества отзывов - абсолютное количество отзывов за выбранный промежуток с определенным шагом
    - Определение аномалий - отображение моментов, когда появилось аномально большое количество положительных/отрицательных отзывов
    - Топ продуктов - сортировка продуктов по наибольшому проценту положительных или отрицательных отзывов
    - Мультивыбор продуктов - возможность выбрать количество продуктов используемых для анализа и выведение их на дашборд
    - Фильтрация по:
        - Источникам
        - Продуктам
        - Тональностям
        - Периоду
    - Загрузка/выгрузка данных через интерфейс
- Модель имеет следующие функции:
    - Парсинг отзывов с агрегаторов
    - Выделение продуктов из отзывов
    - Определение тональности отзыва


## Техническая информация
### Архитектура
![Архитектура проекта](/docs/architecture.png)

### Исследование алгоритмов

В данном разделе представленны результаты исследования отзывов клиентов собранных с [banki.ru](https://www.banki.ru/)

### Описание данных

В результате работы парсера были собранны отзывы:
- **[banki.ru](https://www.banki.ru/)** 
    - число уникальных: 7000 шт.
    - данные представленны в `json` формате со следующими заголовками
        - *title* - заголовок отзыва;
        - *text* - текст отзыва;
        - *date_added* - дата создания отзыва; 

Все результаты эксперементов сохраняются в папку `research_data/experements_results/`
### Описание основных инструментов использованных в исследованиях

- [`Marimo`]() - динамически исполняемый ноутбук`Python` ноутбук
- [`KeyBERT`]() - для выделение ключевых слов в документе;
- [`BERTopic`]() - для тематическое моделирования;
- [`Spacy`]() - для генерации графа связности в предложении и выделения мусорных слов;


### Описание отчётов

В процесе анализа данных, были созданны отчёты, с использованием `marimo` - динамически исполняемых ноутбуков. 

В форме читаемого отчёта, ноутбуки храняться в папке `research_data/reports/`.

Исходный код ноутбуков представлен в папке `research_data/code/`, для запуска ноутбука, нужно выполнить следующий список команд:

- установка необходимых зависимостей, для большего удобства был использован пакетный мэнеджер `poetry`:

    ```bash
    poetry install
    ```

- запуск ноутбука (надо находиться в папке `research_data`):
    - для редактирования  (исполняемый код будет показан):
        ```
        poetry run marimo edit ./code/<имя_необходимого_ноутбука>
        ```
    - для просмотра (исполняемый код **не** будет показан)
        ```
        poetry run marimo run ./code/<имя_необходимого_ноутбука>
        ```

#### Поиск топиков

Для поиска основных тем, существует несколько подходов:

- Кластеризация - стандартные алгоритмы кластеризации:
    - являются понятными/легко интерпритируемыми
    - позволяют легко оценивать полученный результат (локоть силуета)
    - но не позволяют легко оценивать поднятые топики внутри документа, т.е. документы предварительно надо ещё разделить 
- LDA - является стандартным подходом для тематического моделирования
    - слишком медленный и долгий
- BERTopic - современный подход заменивший LDA и объединяющий в себе ещё и кластеризацию

#### Проверка метода KNN для выделенных топиков `./code/test_classification.py`

В данном ноутбуке проверяется гипотиза для классификации по топикам через поиск наиболее близкого по косинусному растоянию и подбираются модели 


#### Тематическое моделирование данных `./code/topic_modelling.py`

В данном ноутбуке, помимо класического `BERTopic`, была рассмотрена его модификация с заменой `HDBSCAN` на `KMeans`

В добавок был рассмотрен алгоритм, который, помимо разбиения отзыва на подтемы, через представление представление его как графа леса и удаления слабых рёбер (рёбра писывающие отношение *`conj`*). При таком разбиении, себя лучше показывает модель `ai-forever/sbert_large_nlu_ru`

Для представления предложения в виде графа использовался [функционал](https://spacy.io/usage/visualizers) библиотеки `Spacy`


#### Обучение сентементальной модели `train_sentiment_models.py`

При проверки семантических моделей, было выявленны следующие недостатки:

1. Большинство данных моделей имеют архитектуру `BERT`, что для такой простой задачи, не самое наилучшее решение, а так как в процессе работы алгоритма отзывы векторизуются - можно обучить `CatBoost` (как наиболее эффективную модель) исходя из логики - плохой *grade* - негативный отзыв


#### Описание работы итогового алгоритма

- Дано:
    - Векторезатор: $V : Str \rightarrow \mathbb{R}^n$
    - Список топиков: $\mathbb{T} = \{x:Str\}$
    - Нижний предел для соответсвия подтексту топика: $\lambda \in \mathbb{R}$
    - Нижний предел для осмысленности топика: $k \in \mathbb{N}$

- Подготовительный этап: 
    1. Векторизуем топики

- Алгоритм
    1. На вход подаётся список отзывов $L_{reviews} = \{x:Str\}$
    2. Каждый из отзывов разбивается на подтекста (см. `../research`) $\overline{L}_{reviews} = {x:{a:Str}}$
    3. Убираются подтексты с числом слов меньше $k$
    4. Каждый подтекст вектаризуется с помощью векторизатора $V$
    5. Над порождённым под действием $V$ пространством можно задать метрику $d: \mathbb{R^n} \times \mathbb{R^n} \rightarrow  \mathbb{R}$ (для текстовых эмбедингов себя зарекомендовала косинусное расстояние)
    6. Для каждой вектаризованной подтемы ищем наиболее близкй вектаризованный топик
    7. Убираем все топики, метрика для которых была меньше $\lambda$


    ##### Преимущества данного подхода
    
    1. Сохраняется абстрактность алгоритма, из-за чего появляется высокая расширяемость
    2. Легковестность данного подхода, слабая зависимость от *GPU*
    3. Не требует обучение моделей и вызываемых с этим сложностей (разметка данных)

    ##### Недостатки

    1. Является эвристикой
    2. Менее точный предобученных моделей

Общие технические материалы по проекту собраны в папке [`docs`](docs),
в том числе там находится (относительно) актуальная Postman-коллекция и схема сущностей.

### Клиентская часть проекта (фронтэнд системы) включает в себя веб-приложение:

- [`adera-dashboard`](packages/frontend/adera-dashboard) (`d:`) – веб-приложение на React (Vite), интерфейс дашборда

Общий для всех веб-приложений код вынесен во внутренние библиотеки:

- [`@adera/auth-fetch`](packages/frontend/lib/auth-fetch) (`af:`) – React-провайдер всего необходимого для авторизации и запросов к API
- [`@adera/ui`](packages/frontend/lib/ui) (`ui:`) – UI-кит проекта, общие для веб-приложений стили, компоненты и утилиты
- [`@adera/eslint-plugin-import-paths`](packages/frontend/lib/eslint-plugin-import-paths) (`ip:`) – плагин для ESLint, правильно исправляет импорты на абсолютные и относительные

Детальную информацию по конкретным пакетам ищите в их собственных `README.md`.

### Развертывание

Развертывание проекта происходит с использованием возможностей docker и docker compose.

Прежде всего, необходимо установить на систему Yarn и выполнить yarn install из корня репозитория.

#### Postgres

Для инициализации БД с данными, полученными нашими парсерами, необходимо заполнить окружение .env согласно .env.example в директории packages/backend/postgres. После этого, можно запускать контейнер с пустой БД с помощью docker compose up из той же директории.

Далее необходимо променить к БД миграции и затем запустить скрипт заполнения БД. 

Для применения миграций в директории packages/backend/adera-core выполнить следующую команду:
```
yarn knex-cli:local --knexfile ./db/knexfile.mjs migrate:latest
```

Схема БД актуализирована, теперь необходимо запустить скрипт заполнения БД.

Для этого на систему необходимо поставить менеджер зависимостей poetry.

После этого в директории scripts создать окружение для скрипта заполнения БД .env согласно .env.example

После этого можно подготавливать окружение для скрипта и запускать скрипт:

```
poetry install
```

```
poetry run python db_filler_from_flat_data/main.py
```

После этого, в БД окажутся актуальные данные и правильная схема данных.

#### Backend и инфраструктура

Для развертывания backend составляющей приложения сначала необходимо поднять контейнеры, описанные с помощью docker compose в директории _docker.

Перед развертыванием в директориях _docker и packages/backend/adera-core должны быть созданы файлы окружения .env, которые должны быть развернуты в соответствии с примерами .env.example соответственно для каждой директории, стоит отметить, что переменные окружения S3_ACCESS_KEY и S3_SECRET_KEY во время первого запуска будут пусты.

После того как все переменные окружения (кроме S3_ACCESS_KEY и S3_SECRET_KEY) заполнены, необходимо произвести запуск контейнеров из директории _docker командой docker compose up. Далее необходимо перейти в консоль minio с помощью данных для входа указанных в окружении, создать bucket с названием box (Важно!) и создать access key для доступа к minio. После этого полученные access и secret ключи нужно занести в окружение adera-core, после чего перезапустить контейнеры, чтобы изменения применились. 

После этого, бэкенд будет доступен на порте 3000.

#### Frontend

Для развертывания frontend составляющей сервиса необходимо заполнить .env согласно .env.example в директории packages/frontend/adera-dashboard

После этого необходимо последовательно выполнить следующие команды из корня репозитория:
```
docker build -t adera-dashboard -f packages/frontend/adera-dashboard/Dockerfile .
```
```
docker stop adera-dashboard-container || true && docker rm adera-dashboard-container || true
```

```
docker run -d -p 5173:8080 --name adera-dashboard-container --env-file packages/frontend/adera-dashboard/.env adera-dashboard
```

После этого, фронтенд будет доступен на порте 5173.

#### ML services

Для развертывания сервиса ML необходимо обращаться к README в директории ml_pipeline_service

#### Парсер

Для развертывания парсера(необязательно) необходимо обращаться к README в директории reviews_parser

### Разработка

Здесь используются (и уже настроены) современная версия [Yarn 2+](https://yarnpkg.com/getting-started/migration) и [Yarn Workspaces](https://yarnpkg.com/features/workspaces) –
достаточно один раз выполнить команду **`yarn install`** из корня репозитория,
чтобы установить зависимости сразу для всех входящих в него JS-пакетов, используя один общий `yarn.lock`.

Главы в этот раздел добавляются исходя из потребностей (и запросов!) разработчиков –
обязательно сообщите, если здесь не хватает какой-либо информации.

#### Окружение

Для упрощения локальной работы с внешними зависимостями в папке `_docker` лежит файл `docker-compose.yml`.
Достаточно выполнить там команду **`docker-compose up -d`**
для автоматической установки и запуска всех необходимых инструментов в формате Docker-контейнеров.

#### Команды

Yarn позволяет контролировать отдельные пакеты (workspaces) прямо из корня моно-репозитория.
Например, можно использовать команду **`yarn workspace adera-dashboard dev`**
(или даже просто **`yarn d:dev`** – см. [Yarn Global Scripts](https://yarnpkg.com/features/workspaces#global-scripts))
для запуска конкретного сервиса.

### Инфраструктура

Требуются **PostgreSQL**

#### `adera-dashboard`

- Собранное в статику веб-приложение
- Не требует никаких внешних зависимостей
- Ожидает найти себя на корне отдельного домена и само контролирует роутинг
- Отправляет запросы к `backend_name` на `/api`
